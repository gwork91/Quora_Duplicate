{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating DF with features and duplicate variable only for final model\n",
    "def append_df(df1, df2):\n",
    "    # df1 with column names, and df2 without\n",
    "    df2.columns = df1.columns\n",
    "    df1 = df1.append(df2, ignore_index=True)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id            2345796\n",
       "q1_form_len        2345796\n",
       "q2_form_len        2345796\n",
       "q1_length          2345796\n",
       "q2_length          2345796\n",
       "q1_unique          2345796\n",
       "q2_unique          2345796\n",
       "q1_form_uni        2345796\n",
       "q2_form_uni        2345796\n",
       "q1_form_char       2345796\n",
       "q2_form_char       2345796\n",
       "q1_q2_char_diff    2345796\n",
       "common_cnt         2345796\n",
       "prcnt_common       2345379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_cols1 = pd.read_csv('test_data_cols1.csv', sep=',')\n",
    "test_data_cols2 = pd.read_csv('test_data_cols2.csv', sep=',', skiprows=1, header=None)\n",
    "test_data_cols1 = append_df(test_data_cols1,test_data_cols2) \n",
    "test_data_cols1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_cols1['prcnt_common'].fillna(test_data_cols1['prcnt_common'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id            2345796\n",
       "q1_form_len        2345796\n",
       "q2_form_len        2345796\n",
       "q1_length          2345796\n",
       "q2_length          2345796\n",
       "q1_unique          2345796\n",
       "q2_unique          2345796\n",
       "q1_form_uni        2345796\n",
       "q2_form_uni        2345796\n",
       "q1_form_char       2345796\n",
       "q2_form_char       2345796\n",
       "q1_q2_char_diff    2345796\n",
       "common_cnt         2345796\n",
       "prcnt_common       2345796\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_cols1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_clean(test_data):\n",
    "    # Create Test_ID DF\n",
    "    test_id_col = test_data[\"test_id\"]\n",
    "    test_id_col = pd.DataFrame(pd.Series(test_id_col))\n",
    "    \n",
    "    # Clean Test DF model\n",
    "    test_data.drop(['test_id'], axis=1, inplace=True)\n",
    "    #test_data.drop(['prcnt_common'], axis=1, inplace=True)               # Include this column in the main version-Comment it\n",
    "    \n",
    "    return test_id_col, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this only for the basic only features case\n",
    "test_id_col, test_data_cols1 = test_clean(test_data_cols1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below function for:\n",
    "# 1. Take the Model Path and Name : Load the Model\n",
    "# 2. Take the Test Data with iteration of desired featuers\n",
    "# 3. Take the Test_ID column dataframe\n",
    "# 4. Take the final submission path and file name to be submitted on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_df_create(model_path, model_name, test_data, test_id_col, submission_path, final_file_name):\n",
    "    # Loading the Desired Model\n",
    "    xgb2 = joblib.load(model_path+model_name)\n",
    "    \n",
    "    # Run model on Test Data\n",
    "    test_pred_xgb2 = xgb2.predict(test_data)\n",
    "    test_pred_xgb2 = pd.DataFrame(test_pred_xgb2)\n",
    "    test_pred_xgb2.columns=['is_duplicate']\n",
    "    \n",
    "    # Final Submission DF\n",
    "    submit_df = pd.concat([test_id_col,test_pred_xgb2 ], axis=1)\n",
    "    submit_df.to_csv(test_submission_path+final_file_name, index=False, sep=',')\n",
    "    \n",
    "    # Basis info\n",
    "    print \"Test DF Shape\",(submit_df.shape[0], submit_df.shape[1])\n",
    "    print(submit_df.head())\n",
    "    print('Total 1s : %d' % (test_pred_xgb2.sum()))\n",
    "    print('1s Percentage : %f' % (float(test_pred_xgb2.sum())/float(submit_df.shape[0])*100))\n",
    "    \n",
    "    return(submit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "def test_df_create_prob(model_path, model_name, test_data, test_id_col, submission_path, final_file_name):\n",
    "    # Loading the Desired Model\n",
    "    xgb2 = joblib.load(model_path+model_name)\n",
    "    \n",
    "    # Run model on Test Data\n",
    "    test_pred_xgb2 = xgb2.predict_proba(test_data)\n",
    "    test_pred_xgb2 = pd.DataFrame(test_pred_xgb2)\n",
    "    test_pred_xgb2 = pd.DataFrame(test_pred_xgb2[1])\n",
    "    test_pred_xgb2.columns=['is_duplicate']\n",
    "    \n",
    "    # Final Submission DF\n",
    "    submit_df = pd.concat([test_id_col,test_pred_xgb2 ], axis=1)\n",
    "    submit_df.to_csv(test_submission_path+final_file_name, index=False, sep=',')\n",
    "    \n",
    "    # Basis info\n",
    "    print \"Test DF Shape\",(submit_df.shape[0], submit_df.shape[1])\n",
    "    print(submit_df.head())\n",
    "    print('Total 1s : %d' % (test_pred_xgb2.sum()))\n",
    "    print('1s Percentage : %f' % (float(test_pred_xgb2.sum())/float(submit_df.shape[0])*100))\n",
    "    \n",
    "    return(submit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring on Model of Basic Features (roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path='/home/pgoyal/quora/model/'\n",
    "test_submission_path= '/home/pgoyal/quora/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model-1 :\n",
    "# 1. Basic features only\n",
    "# 2. Hyperparameters set using a validation split data - roc_auc\n",
    "# 3. Final model is trained with the step-2 parameters and trained on the training dataset only (validation part not included!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0             0\n",
      "1        1             1\n",
      "2        2             1\n",
      "3        3             0\n",
      "4        4             0\n",
      "Total 1s : 356786\n",
      "1s Percentage : 15.209592\n"
     ]
    }
   ],
   "source": [
    "# Model-1 : Choose this one only as of now (Score 8.69~) : Model without prcnt_common feature\n",
    "model_name= 'xgb2_dup_auc.pkl'\n",
    "file_name = 'test_submission_1.csv'\n",
    "final_df = test_df_create(model_path, model_name, test_data_cols1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_cols1.drop(['prcnt_common'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.202753\n",
      "1        1      0.518799\n",
      "2        2      0.668572\n",
      "3        3      0.151815\n",
      "4        4      0.179836\n",
      "Total 1s : 596783\n",
      "1s Percentage : 25.440573\n"
     ]
    }
   ],
   "source": [
    "model_path='/home/pgoyal/quora/model/'\n",
    "test_submission_path= '/home/pgoyal/quora/'\n",
    "\n",
    "# Model-1b : With Probability Score, Not chosen (Score 0.46741~) : Model without prcnt_common feature\n",
    "model_name= 'xgb2_dup_auc.pkl'\n",
    "file_name = 'test_submission_1b_7.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_data_cols1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model-2\n",
    "# 1. Basic features & prcnt_common feature also  (So, load the test_data_cols1 dataset again and run this, as prcnt_common is dropped)\n",
    "# 2. Hyperparameters set using a validation split data - roc_auc\n",
    "# 3. Final model is trained with the step-2 parameters and trained on the training dataset only (validation part not included!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0             0\n",
      "1        1             1\n",
      "2        2             1\n",
      "3        3             0\n",
      "4        4             0\n",
      "Total 1s : 928668\n",
      "1s Percentage : 39.588609\n"
     ]
    }
   ],
   "source": [
    "# Model-2 : Not Chosen (Score 14.~)  : Model with prcnt_common\n",
    "model_name= 'xgb2_dup_auc_2.pkl'\n",
    "file_name = 'test_submission_2.csv'\n",
    "final_df = test_df_create(model_path, model_name, test_data_cols1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.358872\n",
      "1        1      0.654270\n",
      "2        2      0.783266\n",
      "3        3      0.260690\n",
      "4        4      0.307835\n",
      "Total 1s : 837069\n",
      "1s Percentage : 35.683831\n"
     ]
    }
   ],
   "source": [
    "# Model-2 : (Model 2 only with probability scores): Not chosen 0.61042 : Model with prcnt_common\n",
    "model_name= 'xgb2_dup_auc_2.pkl'\n",
    "file_name = 'test_submission_2b_8.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_data_cols1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del test_data_cols1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scoring on Model of Basic+Fuzzy Features (roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the test data with the desired basic and Fuzzy features\n",
    "test_basic_fuzzy1 = pd.read_csv('/home/pgoyal/quora/test_basic_fuzzy1.csv', sep=',')\n",
    "for i in [2,3,4,5,6]:\n",
    "    vars()['test_basic_fuzzy'+str(i)] = pd.read_csv('/home/pgoyal/quora/test_basic_fuzzy'+str(i)+'.csv',  sep=',', skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy2)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy3)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy4)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy5)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1_form</th>\n",
       "      <th>question2_form</th>\n",
       "      <th>q1_form_len</th>\n",
       "      <th>q2_form_len</th>\n",
       "      <th>q1_length</th>\n",
       "      <th>q2_length</th>\n",
       "      <th>q1_unique</th>\n",
       "      <th>q2_unique</th>\n",
       "      <th>q1_form_uni</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_q2_char_diff</th>\n",
       "      <th>common_cnt</th>\n",
       "      <th>prcnt_common</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>partial_token_set_ratio</th>\n",
       "      <th>partial_token_sort_ratio</th>\n",
       "      <th>q_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>w_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>surfac pro compar ipad pro</td>\n",
       "      <td>microsoft choos core core home surfac pro</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hair transplant age much cost</td>\n",
       "      <td>much cost hair transplant requir</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>best way send money china us</td>\n",
       "      <td>send money china</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>food emulsifi</td>\n",
       "      <td>food fibr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aberystwyth start read</td>\n",
       "      <td>start read</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                 question1_form  \\\n",
       "0        0     surfac pro compar ipad pro   \n",
       "1        1  hair transplant age much cost   \n",
       "2        2   best way send money china us   \n",
       "3        3                  food emulsifi   \n",
       "4        4         aberystwyth start read   \n",
       "\n",
       "                              question2_form  q1_form_len  q2_form_len  \\\n",
       "0  microsoft choos core core home surfac pro            5            7   \n",
       "1           much cost hair transplant requir            5            5   \n",
       "2                           send money china            6            3   \n",
       "3                                  food fibr            2            2   \n",
       "4                                 start read            3            2   \n",
       "\n",
       "   q1_length  q2_length  q1_unique  q2_unique  q1_form_uni   ...     \\\n",
       "0         11         14         11         13            4   ...      \n",
       "1         14          7         14          7            5   ...      \n",
       "2         14          6         12          6            6   ...      \n",
       "3          4          3          4          3            2   ...      \n",
       "4          4          6          4          6            3   ...      \n",
       "\n",
       "   q1_q2_char_diff  common_cnt  prcnt_common  partial_ratio  \\\n",
       "0               13           2          0.20             56   \n",
       "1                3           4          0.40             71   \n",
       "2                9           3          0.33            100   \n",
       "3                4           1          0.25             56   \n",
       "4               11           2          0.40            100   \n",
       "\n",
       "   partial_token_set_ratio  partial_token_sort_ratio  q_ratio  \\\n",
       "0                      100                        67       30   \n",
       "1                      100                        76       59   \n",
       "2                      100                       100       73   \n",
       "3                      100                        88       64   \n",
       "4                      100                       100       63   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  w_ratio  \n",
       "0               63                54       86  \n",
       "1               93                82       88  \n",
       "2              100                73       90  \n",
       "3               64                64       64  \n",
       "4              100                63       90  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_basic_fuzzy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path='/home/pgoyal/quora/model2/'\n",
    "test_submission_path= '/home/pgoyal/quora/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'test_id', u'question1_form', u'question2_form', u'q1_form_len',\n",
      "       u'q2_form_len', u'q1_length', u'q2_length', u'q1_unique', u'q2_unique',\n",
      "       u'q1_form_uni', u'q2_form_uni', u'q1_form_char', u'q2_form_char',\n",
      "       u'q1_q2_char_diff', u'common_cnt', u'prcnt_common', u'partial_ratio',\n",
      "       u'partial_token_set_ratio', u'partial_token_sort_ratio', u'q_ratio',\n",
      "       u'token_set_ratio', u'token_sort_ratio', u'w_ratio'],\n",
      "      dtype='object')\n",
      "(2345796, 23)\n"
     ]
    }
   ],
   "source": [
    "print test_basic_fuzzy1.columns\n",
    "print test_basic_fuzzy1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id_col = test_basic_fuzzy1[\"test_id\"]\n",
    "test_id_col = pd.DataFrame(pd.Series(test_id_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_basic_fuzzy1.drop(['question1_form','question2_form','test_id'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model-3 : \n",
    "# 1. Basic and Fuzzy features\n",
    "# 2. Hyperparameters set using a validation split data - roc_auc\n",
    "# 3. Final model is trained with the step-2 parameters and trained on the training dataset only (validation part not included!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0             0\n",
      "1        1             1\n",
      "2        2             1\n",
      "3        3             0\n",
      "4        4             0\n",
      "Total 1s : 441040\n",
      "1s Percentage : 18.801294\n"
     ]
    }
   ],
   "source": [
    "# Model-3 : Model with Basic and Fuzzy features with validation split : Not chosen (8.96)\n",
    "model_name= 'xgb2_dup_auc_2.pkl'\n",
    "file_name = 'test_submission_3.csv'\n",
    "final_df = test_df_create(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.120734\n",
      "1        1      0.588195\n",
      "2        2      0.684597\n",
      "3        3      0.279819\n",
      "4        4      0.193473\n",
      "Total 1s : 587186\n",
      "1s Percentage : 25.031442\n"
     ]
    }
   ],
   "source": [
    "# Model-3b : (Model 3 only with probability scores): Not chosen 0.45475\n",
    "model_name= 'xgb2_dup_auc_2.pkl'\n",
    "file_name = 'test_submission_3b_6.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model-4 : \n",
    "# 1. Basic and Fuzzy features\n",
    "# 2. Hyperparameters set using a validation split data - roc_auc\n",
    "# 3. Final model is trained with the step-2 parameters and trained on the overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0             0\n",
      "1        1             1\n",
      "2        2             1\n",
      "3        3             0\n",
      "4        4             0\n",
      "Total 1s : 438643\n",
      "1s Percentage : 18.699111\n"
     ]
    }
   ],
   "source": [
    "# Model-4 : Not at top\n",
    "model_name= 'xgb_dup_auc_final.pkl'\n",
    "file_name = 'test_submission_4.csv'\n",
    "final_df = test_df_create(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.112291\n",
      "1        1      0.610998\n",
      "2        2      0.679616\n",
      "3        3      0.292897\n",
      "4        4      0.206938\n",
      "Total 1s : 586805\n",
      "1s Percentage : 25.015189\n"
     ]
    }
   ],
   "source": [
    "# Model-4b :  (Model 4 only with probability scores) : Chosen 0.45414\n",
    "model_name= 'xgb_dup_auc_final.pkl'\n",
    "file_name = 'test_submission_4b_5.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scoring on Model of Basic+Fuzzy Features (log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the test data with the desired basic and Fuzzy features (Issue of file upload size, so broken in chunks and loaded)\n",
    "test_basic_fuzzy1 = pd.read_csv('/home/pgoyal/quora/test_basic_fuzzy1.csv', sep=',')\n",
    "for i in [2,3,4,5,6]:\n",
    "    vars()['test_basic_fuzzy'+str(i)] = pd.read_csv('/home/pgoyal/quora/test_basic_fuzzy'+str(i)+'.csv',  sep=',', skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1_form</th>\n",
       "      <th>question2_form</th>\n",
       "      <th>q1_form_len</th>\n",
       "      <th>q2_form_len</th>\n",
       "      <th>q1_length</th>\n",
       "      <th>q2_length</th>\n",
       "      <th>q1_unique</th>\n",
       "      <th>q2_unique</th>\n",
       "      <th>q1_form_uni</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_q2_char_diff</th>\n",
       "      <th>common_cnt</th>\n",
       "      <th>prcnt_common</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>partial_token_set_ratio</th>\n",
       "      <th>partial_token_sort_ratio</th>\n",
       "      <th>q_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>w_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>surfac pro compar ipad pro</td>\n",
       "      <td>microsoft choos core core home surfac pro</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hair transplant age much cost</td>\n",
       "      <td>much cost hair transplant requir</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>best way send money china us</td>\n",
       "      <td>send money china</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>food emulsifi</td>\n",
       "      <td>food fibr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aberystwyth start read</td>\n",
       "      <td>start read</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                 question1_form  \\\n",
       "0        0     surfac pro compar ipad pro   \n",
       "1        1  hair transplant age much cost   \n",
       "2        2   best way send money china us   \n",
       "3        3                  food emulsifi   \n",
       "4        4         aberystwyth start read   \n",
       "\n",
       "                              question2_form  q1_form_len  q2_form_len  \\\n",
       "0  microsoft choos core core home surfac pro            5            7   \n",
       "1           much cost hair transplant requir            5            5   \n",
       "2                           send money china            6            3   \n",
       "3                                  food fibr            2            2   \n",
       "4                                 start read            3            2   \n",
       "\n",
       "   q1_length  q2_length  q1_unique  q2_unique  q1_form_uni   ...     \\\n",
       "0         11         14         11         13            4   ...      \n",
       "1         14          7         14          7            5   ...      \n",
       "2         14          6         12          6            6   ...      \n",
       "3          4          3          4          3            2   ...      \n",
       "4          4          6          4          6            3   ...      \n",
       "\n",
       "   q1_q2_char_diff  common_cnt  prcnt_common  partial_ratio  \\\n",
       "0               13           2          0.20             56   \n",
       "1                3           4          0.40             71   \n",
       "2                9           3          0.33            100   \n",
       "3                4           1          0.25             56   \n",
       "4               11           2          0.40            100   \n",
       "\n",
       "   partial_token_set_ratio  partial_token_sort_ratio  q_ratio  \\\n",
       "0                      100                        67       30   \n",
       "1                      100                        76       59   \n",
       "2                      100                       100       73   \n",
       "3                      100                        88       64   \n",
       "4                      100                       100       63   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  w_ratio  \n",
       "0               63                54       86  \n",
       "1               93                82       88  \n",
       "2              100                73       90  \n",
       "3               64                64       64  \n",
       "4              100                63       90  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy2)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy3)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy4)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy5)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy6)\n",
    "print test_basic_fuzzy1.shape\n",
    "test_basic_fuzzy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path='/home/pgoyal/quora/model3/'\n",
    "test_submission_path= '/home/pgoyal/quora/'\n",
    "test_id_col = test_basic_fuzzy1[\"test_id\"]\n",
    "test_id_col = pd.DataFrame(pd.Series(test_id_col))\n",
    "test_basic_fuzzy1.drop(['question1_form','question2_form','test_id'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model-5 : \n",
    "# 1. Basic and Fuzzy features\n",
    "# 2. Hyperparameters set using a validation split data - log_loss (initial hyperparam from Model-4)\n",
    "# 3. Final model is trained with the step-2 parameters and trained on the training dataset only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.117726\n",
      "1        1      0.604464\n",
      "2        2      0.706178\n",
      "3        3      0.258797\n",
      "4        4      0.195440\n",
      "Total 1s : 583877\n",
      "1s Percentage : 24.890365\n"
     ]
    }
   ],
   "source": [
    "# Model-5 : (validation part not included!)\n",
    "model_name= 'xgb_log2_dup_logloss.pkl'\n",
    "file_name = 'test_submission_5.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.123649\n",
      "1        1      0.625843\n",
      "2        2      0.684863\n",
      "3        3      0.288893\n",
      "4        4      0.218868\n",
      "Total 1s : 584091\n",
      "1s Percentage : 24.899480\n"
     ]
    }
   ],
   "source": [
    "# Model-5b : (with prediction score in the final output and trained on full dataset)\n",
    "model_name= 'xgb_log3_dup_logloss.pkl'\n",
    "file_name = 'test_submission_5b_9.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0             0\n",
      "1        1             1\n",
      "2        2             1\n",
      "3        3             0\n",
      "4        4             0\n",
      "Total 1s : 441179\n",
      "1s Percentage : 18.807219\n"
     ]
    }
   ],
   "source": [
    "# Model-5c : (with 0 or 1 in the final output)\n",
    "model_name= 'xgb_log3_dup_logloss.pkl'\n",
    "file_name = 'test_submission_5c_10.csv'\n",
    "final_df = test_df_create(model_path, model_name, test_basic_fuzzy1, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scoring on Model of Basic+Fuzzy+Similarity Features (log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1_form</th>\n",
       "      <th>question2_form</th>\n",
       "      <th>q1_form_len</th>\n",
       "      <th>q2_form_len</th>\n",
       "      <th>q1_length</th>\n",
       "      <th>q2_length</th>\n",
       "      <th>q1_unique</th>\n",
       "      <th>q2_unique</th>\n",
       "      <th>q1_form_uni</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_q2_char_diff</th>\n",
       "      <th>common_cnt</th>\n",
       "      <th>prcnt_common</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>partial_token_set_ratio</th>\n",
       "      <th>partial_token_sort_ratio</th>\n",
       "      <th>q_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>w_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>surfac pro compar ipad pro</td>\n",
       "      <td>microsoft choos core core home surfac pro</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hair transplant age much cost</td>\n",
       "      <td>much cost hair transplant requir</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>59</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>best way send money china us</td>\n",
       "      <td>send money china</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>food emulsifi</td>\n",
       "      <td>food fibr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aberystwyth start read</td>\n",
       "      <td>start read</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                 question1_form  \\\n",
       "0        0     surfac pro compar ipad pro   \n",
       "1        1  hair transplant age much cost   \n",
       "2        2   best way send money china us   \n",
       "3        3                  food emulsifi   \n",
       "4        4         aberystwyth start read   \n",
       "\n",
       "                              question2_form  q1_form_len  q2_form_len  \\\n",
       "0  microsoft choos core core home surfac pro            5            7   \n",
       "1           much cost hair transplant requir            5            5   \n",
       "2                           send money china            6            3   \n",
       "3                                  food fibr            2            2   \n",
       "4                                 start read            3            2   \n",
       "\n",
       "   q1_length  q2_length  q1_unique  q2_unique  q1_form_uni   ...     \\\n",
       "0         11         14         11         13            4   ...      \n",
       "1         14          7         14          7            5   ...      \n",
       "2         14          6         12          6            6   ...      \n",
       "3          4          3          4          3            2   ...      \n",
       "4          4          6          4          6            3   ...      \n",
       "\n",
       "   q1_q2_char_diff  common_cnt  prcnt_common  partial_ratio  \\\n",
       "0               13           2          0.20             56   \n",
       "1                3           4          0.40             71   \n",
       "2                9           3          0.33            100   \n",
       "3                4           1          0.25             56   \n",
       "4               11           2          0.40            100   \n",
       "\n",
       "   partial_token_set_ratio  partial_token_sort_ratio  q_ratio  \\\n",
       "0                      100                        67       30   \n",
       "1                      100                        76       59   \n",
       "2                      100                       100       73   \n",
       "3                      100                        88       64   \n",
       "4                      100                       100       63   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  w_ratio  \n",
       "0               63                54       86  \n",
       "1               93                82       88  \n",
       "2              100                73       90  \n",
       "3               64                64       64  \n",
       "4              100                63       90  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the test data with the desired basic and Fuzzy features (Issue of file upload size, so broken in chunks and loaded)\n",
    "test_basic_fuzzy1 = pd.read_csv('/home/pgoyal/quora/test_basic_fuzzy1.csv', sep=',')\n",
    "for i in [2,3,4,5,6]:\n",
    "    vars()['test_basic_fuzzy'+str(i)] = pd.read_csv('/home/pgoyal/quora/test_basic_fuzzy'+str(i)+'.csv',  sep=',', skiprows=1, header=None)\n",
    "\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy2)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy3)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy4)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy5)\n",
    "test_basic_fuzzy1 = append_df(test_basic_fuzzy1, test_basic_fuzzy6)\n",
    "print test_basic_fuzzy1.shape\n",
    "test_basic_fuzzy1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>q1_freq_in_q1</th>\n",
       "      <th>q2_freq_in_q2</th>\n",
       "      <th>q1_freq_in_q1q2</th>\n",
       "      <th>q2_freq_in_q1q2</th>\n",
       "      <th>cosine_val</th>\n",
       "      <th>cityblock_val</th>\n",
       "      <th>jaccard_val</th>\n",
       "      <th>canberra_val</th>\n",
       "      <th>euclidean_val</th>\n",
       "      <th>minkowski_val</th>\n",
       "      <th>braycurtis_val</th>\n",
       "      <th>skew_que1</th>\n",
       "      <th>skew_que2</th>\n",
       "      <th>kurt_que1</th>\n",
       "      <th>kurt_que2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>45.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.10</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.98</td>\n",
       "      <td>27.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.43</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>36.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.04</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>65.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.34</td>\n",
       "      <td>4.67</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>42.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.51</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  q1_freq_in_q1  q2_freq_in_q2  q1_freq_in_q1q2  q2_freq_in_q1q2  \\\n",
       "0        0              1              1                1                1   \n",
       "1        1              1              1                2                2   \n",
       "2        2              1              1                1                1   \n",
       "3        3              1              1                1                1   \n",
       "4        4              1              1                1                1   \n",
       "\n",
       "   cosine_val  cityblock_val  jaccard_val  canberra_val  euclidean_val  \\\n",
       "0        0.94          45.27          1.0         91.10           3.32   \n",
       "1        0.98          27.29          1.0         72.43           1.93   \n",
       "2        0.96          36.57          1.0         87.04           2.68   \n",
       "3        0.90          65.77          1.0        112.34           4.67   \n",
       "4        0.95          42.86          1.0         91.51           3.04   \n",
       "\n",
       "   minkowski_val  braycurtis_val  skew_que1  skew_que2  kurt_que1  kurt_que2  \n",
       "0           1.51            0.17       0.15       0.04      -0.19      -0.07  \n",
       "1           0.86            0.11       0.04       0.07      -0.01       0.13  \n",
       "2           1.22            0.14       0.03      -0.01      -0.04      -0.13  \n",
       "3           2.09            0.23       0.05       0.10       0.14      -0.10  \n",
       "4           1.36            0.17       0.07       0.15      -0.06      -0.08  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and merge another test dataset\n",
    "test_w2v_feats1 = pd.read_csv('/home/pgoyal/quora/test_w2v_feats1.csv', sep=',')\n",
    "for i in [2,3]:\n",
    "    vars()['test_w2v_feats'+str(i)] = pd.read_csv('/home/pgoyal/quora/test_w2v_feats'+str(i)+'.csv',  sep=',', skiprows=1, header=None)\n",
    "\n",
    "test_w2v_feats1 = append_df(test_w2v_feats1, test_w2v_feats2)\n",
    "test_w2v_feats1 = append_df(test_w2v_feats1, test_w2v_feats3)\n",
    "print test_w2v_feats1.shape\n",
    "test_w2v_feats1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'test_id', u'question1_form', u'question2_form', u'q1_form_len',\n",
      "       u'q2_form_len', u'q1_length', u'q2_length', u'q1_unique', u'q2_unique',\n",
      "       u'q1_form_uni', u'q2_form_uni', u'q1_form_char', u'q2_form_char',\n",
      "       u'q1_q2_char_diff', u'common_cnt', u'prcnt_common', u'partial_ratio',\n",
      "       u'partial_token_set_ratio', u'partial_token_sort_ratio', u'q_ratio',\n",
      "       u'token_set_ratio', u'token_sort_ratio', u'w_ratio'],\n",
      "      dtype='object')\n",
      "(2345796, 23)\n",
      "Index([u'test_id', u'q1_freq_in_q1', u'q2_freq_in_q2', u'q1_freq_in_q1q2',\n",
      "       u'q2_freq_in_q1q2', u'cosine_val', u'cityblock_val', u'jaccard_val',\n",
      "       u'canberra_val', u'euclidean_val', u'minkowski_val', u'braycurtis_val',\n",
      "       u'skew_que1', u'skew_que2', u'kurt_que1', u'kurt_que2'],\n",
      "      dtype='object')\n",
      "(2345796, 16)\n"
     ]
    }
   ],
   "source": [
    "print test_basic_fuzzy1.columns\n",
    "print test_basic_fuzzy1.shape\n",
    "print test_w2v_feats1.columns\n",
    "print test_w2v_feats1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_basic_fuzzy1.drop(['question1_form','question2_form'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'test_id', u'q1_freq_in_q1', u'q2_freq_in_q2', u'q1_freq_in_q1q2',\n",
      "       u'q2_freq_in_q1q2', u'cosine_val', u'cityblock_val', u'jaccard_val',\n",
      "       u'canberra_val', u'euclidean_val', u'minkowski_val', u'braycurtis_val',\n",
      "       u'skew_que1', u'skew_que2', u'kurt_que1', u'kurt_que2', u'q1_form_len',\n",
      "       u'q2_form_len', u'q1_length', u'q2_length', u'q1_unique', u'q2_unique',\n",
      "       u'q1_form_uni', u'q2_form_uni', u'q1_form_char', u'q2_form_char',\n",
      "       u'q1_q2_char_diff', u'common_cnt', u'prcnt_common', u'partial_ratio',\n",
      "       u'partial_token_set_ratio', u'partial_token_sort_ratio', u'q_ratio',\n",
      "       u'token_set_ratio', u'token_sort_ratio', u'w_ratio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Join both the dataframes test_basic_fuzzy1 and test_w2v_feats1 on 'test_id' column\n",
    "test_final = pd.merge(test_w2v_feats1, test_basic_fuzzy1, left_on=['test_id'],right_on=['test_id'],how='inner', right_index=False)\n",
    "print test_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path='/home/pgoyal/quora/model4/'\n",
    "test_submission_path= '/home/pgoyal/quora/'\n",
    "test_id_col = test_final[\"test_id\"]\n",
    "test_id_col = pd.DataFrame(pd.Series(test_id_col))\n",
    "test_final.drop(['test_id'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 35)\n",
      "Index([u'q1_freq_in_q1', u'q2_freq_in_q2', u'q1_freq_in_q1q2',\n",
      "       u'q2_freq_in_q1q2', u'cosine_val', u'cityblock_val', u'jaccard_val',\n",
      "       u'canberra_val', u'euclidean_val', u'minkowski_val', u'braycurtis_val',\n",
      "       u'skew_que1', u'skew_que2', u'kurt_que1', u'kurt_que2', u'q1_form_len',\n",
      "       u'q2_form_len', u'q1_length', u'q2_length', u'q1_unique', u'q2_unique',\n",
      "       u'q1_form_uni', u'q2_form_uni', u'q1_form_char', u'q2_form_char',\n",
      "       u'q1_q2_char_diff', u'common_cnt', u'prcnt_common', u'partial_ratio',\n",
      "       u'partial_token_set_ratio', u'partial_token_sort_ratio', u'q_ratio',\n",
      "       u'token_set_ratio', u'token_sort_ratio', u'w_ratio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the final columns order here\n",
    "print test_final.shape\n",
    "print test_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model-6 : \n",
    "# 1. Basic, Fuzzy and Similarity features\n",
    "# 2. Hyperparameters set using a validation split data - log_loss (initial hyperparam from Model-4)\n",
    "# 3. Final model is trained with the step-2 parameters and trained on the training dataset only (validation part not included!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.025245\n",
      "1        1      0.517904\n",
      "2        2      0.467295\n",
      "3        3      0.152954\n",
      "4        4      0.117440\n",
      "Total 1s : 339378\n",
      "1s Percentage : 14.467504\n"
     ]
    }
   ],
   "source": [
    "# Model-6 : Model with GridSearch till param8 only (validation part not included!)\n",
    "model_name= 'xgb_log2_dup_logloss.pkl'\n",
    "file_name = 'test_submission_6.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_final, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.025391\n",
      "1        1      0.573217\n",
      "2        2      0.497429\n",
      "3        3      0.237450\n",
      "4        4      0.104594\n",
      "Total 1s : 340001\n",
      "1s Percentage : 14.494058\n"
     ]
    }
   ],
   "source": [
    "# Model-6 : Model with GridSearch till param8 only (validation part included!)\n",
    "model_name= 'xgb_dup_logloss.pkl'\n",
    "file_name = 'test_submission_6f_16.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_final, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.027858\n",
      "1        1      0.477014\n",
      "2        2      0.527143\n",
      "3        3      0.205686\n",
      "4        4      0.120535\n",
      "Total 1s : 334116\n",
      "1s Percentage : 14.243189\n"
     ]
    }
   ],
   "source": [
    "# Model-6 : Model with GridSearch till param9 with best set (validation part not included!)\n",
    "model_name= 'xgb_log2b_dup_logloss.pkl'\n",
    "file_name = 'test_submission_6c_13.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_final, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.017497\n",
      "1        1      0.550115\n",
      "2        2      0.470525\n",
      "3        3      0.209268\n",
      "4        4      0.109565\n",
      "Total 1s : 334537\n",
      "1s Percentage : 14.261169\n"
     ]
    }
   ],
   "source": [
    "# Model-6b : (with prediction score in the final output and trained on full dataset with param9)\n",
    "model_name= 'xgb_log3_dup_logloss.pkl'\n",
    "file_name = 'test_submission_6b_12.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_final, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0             0\n",
      "1        1             1\n",
      "2        2             0\n",
      "3        3             0\n",
      "4        4             0\n",
      "Total 1s : 151082\n",
      "1s Percentage : 6.440543\n"
     ]
    }
   ],
   "source": [
    "# Model-6c : (with prediction binary in the final output and trained on full dataset with param9)\n",
    "model_name= 'xgb_log3_dup_logloss.pkl'\n",
    "file_name = 'test_submission_6e_15.csv'\n",
    "final_df = test_df_create(model_path, model_name, test_final, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DF Shape (2345796, 2)\n",
      "   test_id  is_duplicate\n",
      "0        0      0.025254\n",
      "1        1      0.588287\n",
      "2        2      0.488603\n",
      "3        3      0.195160\n",
      "4        4      0.123961\n",
      "Total 1s : 341539\n",
      "1s Percentage : 14.559635\n"
     ]
    }
   ],
   "source": [
    "# Model-6d :  Hyperparameter tuning NOT DONE (with prediction score in the final output and trained on train part of dataset)\n",
    "model_name= 'xgb_log1_dup_logloss.pkl'\n",
    "file_name = 'test_submission_6d_14.csv'\n",
    "final_df = test_df_create_prob(model_path, model_name, test_final, test_id_col,  test_submission_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the Geometric mean ensemble script on the following solutions as these are the best ones till now  :\n",
    "# test_submission_6.csv\n",
    "# test_submission_6b_12.csv\n",
    "# test_submission_6c_13.csv\n",
    "# test_submission_6d_14.csv\n",
    "# test_submission_6f_16.csv\n",
    "\n",
    "# Final output file : test_submission_geomean.csv\n",
    "\n",
    "# Tried with Rank Average script as well : but not better results as compared to geom mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try with weight ensemble techniques later on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
